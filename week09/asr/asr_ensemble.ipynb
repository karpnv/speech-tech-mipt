{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cb18d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Tuple, List\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sentencepiece\n",
    "import omegaconf\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.models import ConformerLAS, ConformerCTC\n",
    "from src.metrics import WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bb692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(model: pl.LightningModule, ckpt_path: str) -> pl.LightningModule:\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    model.load_state_dict(ckpt)\n",
    "    model.eval()\n",
    "    model.freeze()\n",
    "    return model\n",
    "\n",
    "\n",
    "def compute_wer(refs: Iterable[str], hyps: Iterable[str]) -> float:\n",
    "    wer = WER()\n",
    "    wer.update(refs, hyps)\n",
    "    return wer.compute()[0].item()\n",
    "\n",
    "\n",
    "class GreedyDecoderLAS:\n",
    "    def __init__(self, model: ConformerLAS, max_steps=20):\n",
    "        self.model = model\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "    def __call__(self, encoded: torch.Tensor) -> str:\n",
    "        \n",
    "        tokens = [self.model.decoder.tokenizer.bos_id()]\n",
    "\n",
    "        for _ in range(self.max_steps):\n",
    "            \n",
    "            tokens_batch = torch.tensor(tokens).unsqueeze(0)\n",
    "            att_mask = self.model.make_attention_mask(torch.tensor([tokens_batch.size(-1)]))\n",
    "            \n",
    "            distribution = self.model.decoder(\n",
    "                encoded=encoded, encoded_pad_mask=None,\n",
    "                target=tokens_batch, target_mask=att_mask, target_pad_mask=None\n",
    "            )\n",
    "        \n",
    "            best_next_token = distribution[0, -1].argmax()\n",
    "            \n",
    "            if best_next_token == self.model.decoder.tokenizer.eos_id():\n",
    "                break\n",
    "\n",
    "            tokens.append(best_next_token.item())\n",
    "        \n",
    "        return self.model.decoder.tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7489a3",
   "metadata": {},
   "source": [
    "# Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd256ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'test_opus/farfield/manifest.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87d7a33",
   "metadata": {},
   "source": [
    "## LAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eff477",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = omegaconf.OmegaConf.load(\"./conf/conformer_las.yaml\")\n",
    "conf.val_dataloader.dataset.manifest_name = dataset\n",
    "conf.model.decoder.tokenizer = \"./data/tokenizer/bpe_1024_bos_eos.model\"\n",
    "\n",
    "conformer_las = init_model(\n",
    "    model=ConformerLAS(conf=conf),\n",
    "    ckpt_path=\"./data/conformer_las_2epochs.ckpt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1343a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "las_decoder = GreedyDecoderLAS(conformer_las)\n",
    "\n",
    "refs, hyps_las = [], []\n",
    "\n",
    "for batch in tqdm(conformer_las.val_dataloader()):\n",
    "\n",
    "    features, features_len, targets, target_len = batch\n",
    "\n",
    "    encoded, encoded_len = conformer_las(features, features_len)\n",
    "    \n",
    "    for i in range(features.shape[0]):\n",
    "\n",
    "        encoder_states = encoded[\n",
    "            [i],\n",
    "            :encoded_len[i],\n",
    "            :\n",
    "        ]\n",
    "\n",
    "        ref_tokens = targets[i, :target_len[i]].tolist()\n",
    "\n",
    "        refs.append(\n",
    "            conformer_las.decoder.tokenizer.decode(ref_tokens)\n",
    "        )\n",
    "        hyps_las.append(\n",
    "            las_decoder(encoder_states)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05af7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_wer(refs, hyps_las)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262680b9",
   "metadata": {},
   "source": [
    "## CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca9bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load models, estimate WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e8ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_ctc_hyps(model: ConformerCTC) -> Tuple[List[str], List[str]]:\n",
    "    return [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76da07ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = omegaconf.OmegaConf.load(\"./conf/conformer_ctc.yaml\")\n",
    "conf.val_dataloader.dataset.manifest_name = dataset\n",
    "\n",
    "conformer_ctc = init_model(\n",
    "    model=ConformerCTC(conf=conf),\n",
    "    ckpt_path=\"./data/conformer_7epochs_state_dict.ckpt\"\n",
    ")\n",
    "\n",
    "refs, hyps_ctc = decode_ctc_hyps(conformer_ctc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64281db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = omegaconf.OmegaConf.load(\"./conf/conformer_ctc_wide.yaml\")\n",
    "conf.val_dataloader.dataset.manifest_name = dataset\n",
    "\n",
    "conformer_ctc_wide = init_model(\n",
    "    model=ConformerCTC(conf=conf),\n",
    "    ckpt_path=\"./data/conformer_wide_7epochs_state_dict.ckpt\"\n",
    ")\n",
    "\n",
    "refs, hyps_ctc_wide = decode_ctc_hyps(conformer_ctc_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdda104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ba5e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c13f9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f60776f4",
   "metadata": {},
   "source": [
    "# ROVER: Recognizer Output Voting Error Reduction — 5 points\n",
    "\n",
    "* [A post-processing system to yield reduced word error rates: Recognizer Output Voting Error Reduction (ROVER)](https://ieeexplore.ieee.org/document/659110)\n",
    "* [Improved ROVER using Language Model Information](https://www-tlp.limsi.fr/public/asr00_holger.pdf)\n",
    "\n",
    "Alignment + Voting\n",
    "\n",
    "![](./images/rover_table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167e04f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crowdkit.aggregation.texts import ROVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5480795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: aggregate hypotheses, estimate WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d74139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59efe52d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d69158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd329aa4",
   "metadata": {},
   "source": [
    "# MBR: Minimum Bayes Risk — 5 points\n",
    "\n",
    "\n",
    "* [Minimum Bayes Risk Decoding and System\n",
    "Combination Based on a Recursion for Edit Distance](https://danielpovey.com/files/csl11_consensus.pdf)\n",
    "* [mbr-decoding blog-post](https://suzyahyah.github.io/bayesian%20inference/machine%20translation/2022/02/15/mbr-decoding.html)\n",
    "* [Combination of end-to-end and hybrid models for speech recognition](http://www.interspeech2020.org/uploadfile/pdf/Tue-1-8-4.pdf)\n",
    "\n",
    "![](./images/mbr_scheme.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c6e63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: retrieve minimum-Distance hypothesis, estimate WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1fb335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3897daf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2c3499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
