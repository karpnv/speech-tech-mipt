{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd1a61fa",
   "metadata": {},
   "source": [
    "[Transformer Interpretation](https://arxiv.org/pdf/1906.02762.pdf)            |  [Macaron Net](https://arxiv.org/pdf/1906.02762.pdf)\n",
    ":-------------------------:|:-------------------------:\n",
    "![](./images/particle_dynamics.png)  |  ![](./images/macaron_net.png)\n",
    "\n",
    "[Conformer](https://arxiv.org/pdf/2005.08100.pdf)            |  [Transformer](https://arxiv.org/pdf/1706.03762.pdf)\n",
    ":-------------------------:|:-------------------------:\n",
    "![](./images/conformer.png)  |  ![](./images/transformer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d0f6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sentencepiece\n",
    "import omegaconf\n",
    "\n",
    "from src.models import ConformerLAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c51758a",
   "metadata": {},
   "source": [
    "# LAS: Listen Attend and Spell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb0353c",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b7e497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"data/test_opus/crowd/manifest.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfff8e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0848cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text.str.split().explode().value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865a87dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text.str.len().hist(bins=75);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f7021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duration.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ad2895",
   "metadata": {},
   "source": [
    "## tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f18c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = sentencepiece.SentencePieceProcessor(model_file=\"data/tokenizer/bpe_1024_bos_eos.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa23df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode_as_pieces('мама мыла раму')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e016c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode_as_ids('мама мыла раму')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21645689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text.apply(lambda x: len(tokenizer.encode(x))).hist(bins=75);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77342a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.bos_id(), tokenizer.eos_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e0284",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0093a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = omegaconf.OmegaConf.load(\"./conf/conformer_las.yaml\")\n",
    "conf.train_dataloader.batch_size = 4\n",
    "conf.train_dataloader.num_workers = 4\n",
    "conf.model.decoder.tokenizer = \"./data/tokenizer/bpe_1024_bos_eos.model\"\n",
    "\n",
    "\n",
    "model = ConformerLAS(conf=conf)\n",
    "ckpt = torch.load(\"data/conformer_las_2epochs.ckpt\", map_location=\"cpu\")\n",
    "model.load_state_dict(ckpt)\n",
    "model.eval()\n",
    "model.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1268f851",
   "metadata": {},
   "source": [
    "## features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee5a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(model.val_dataloader()))\n",
    "\n",
    "features, features_len, targets, target_len = batch\n",
    "\n",
    "for feature in features:\n",
    "    plt.imshow(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adf7d7c",
   "metadata": {},
   "source": [
    "## loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed1b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded, encoded_len = model(features, features_len)\n",
    "\n",
    "\n",
    "encoded_pad_mask = model.make_pad_mask(encoded_len)\n",
    "\n",
    "targets_outputs = targets[:, 1:] # without bos\n",
    "targets_inputs = targets[:, :-1] # without eos / last pad token\n",
    "target_len -= 1\n",
    "\n",
    "target_pad_mask = model.make_pad_mask(target_len)\n",
    "target_mask = model.make_attention_mask(target_len)\n",
    "\n",
    "logits = model.decoder(encoded, ~encoded_pad_mask, targets_inputs, target_mask, ~target_pad_mask)\n",
    "\n",
    "loss = model.loss(logits.transpose(1, 2), targets_outputs)\n",
    "plt.imshow(loss)\n",
    "plt.colorbar(fraction=0.01)\n",
    "plt.show()\n",
    "plt.imshow(loss * target_pad_mask)\n",
    "plt.colorbar(fraction=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c86a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "(loss * target_pad_mask).sum() / target_pad_mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82142e56",
   "metadata": {},
   "source": [
    "## greedy decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beefdd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyDecoder:\n",
    "    def __init__(self, model, tokenizer, max_steps=20):\n",
    "        self.model = model\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "    def __call__(self, encoded):\n",
    "        \n",
    "        tokens = [self.model.decoder.tokenizer.bos_id()]\n",
    "\n",
    "        for _ in range(self.max_steps):\n",
    "            \n",
    "            tokens_batch = torch.tensor(tokens).unsqueeze(0)\n",
    "            att_mask = self.model.make_attention_mask(torch.tensor([tokens_batch.size(-1)]))\n",
    "            \n",
    "            distribution = self.model.decoder(\n",
    "                encoded=encoded, encoded_pad_mask=None,\n",
    "                target=tokens_batch, target_mask=att_mask, target_pad_mask=None\n",
    "            )\n",
    "        \n",
    "            best_next_token = distribution[0, -1].argmax()\n",
    "            \n",
    "            if best_next_token == self.model.decoder.tokenizer.eos_id():\n",
    "                break\n",
    "\n",
    "            tokens.append(best_next_token.item())\n",
    "        \n",
    "        return self.model.decoder.tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb94cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(model.val_dataloader()))\n",
    "\n",
    "features, features_len, targets, target_len = batch\n",
    "\n",
    "encoded, encoded_len = model(features, features_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f27cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = GreedyDecoder(model, tokenizer)\n",
    "\n",
    "\n",
    "for i in range(features.shape[0]):\n",
    "\n",
    "    encoder_states = encoded[\n",
    "        [i],\n",
    "        :encoded_len[i],\n",
    "        :\n",
    "    ]\n",
    "    \n",
    "    ref_tokens = targets[i, :target_len[i]].tolist()\n",
    "    \n",
    "    print(f\"reference : {tokenizer.decode(ref_tokens)}\")\n",
    "    print(f\"hypothesis: {decoder(encoder_states)}\")\n",
    "    print(\"#\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de036b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c4c53d1",
   "metadata": {},
   "source": [
    "## beam search decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d16f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearchDecoder:\n",
    "    \n",
    "    def __init__(self, model, temp=1.0, beam_size=5, max_steps=20):\n",
    "        self.model = model\n",
    "        self.temp = temp\n",
    "        self.beam_size = beam_size\n",
    "        self.max_steps = max_steps\n",
    "        \n",
    "    def __call__(self, encoded):\n",
    "        \n",
    "        partial_hyps= [(0.0, [self.model.decoder.tokenizer.bos_id()])]\n",
    "        final_hyps = []\n",
    "\n",
    "        while len(partial_hyps) > 0:\n",
    "            \n",
    "            cur_partial_score, cur_partial_hyp = heapq.heappop(partial_hyps)\n",
    "            \n",
    "            tokens_batch = torch.tensor(cur_partial_hyp).unsqueeze(0)\n",
    "            att_mask = self.model.make_attention_mask(torch.tensor([tokens_batch.size(-1)]))\n",
    "            \n",
    "            logits = self.model.decoder(\n",
    "                encoded=encoded, encoded_pad_mask=None,\n",
    "                target=tokens_batch, target_mask=att_mask, target_pad_mask=None\n",
    "            )\n",
    "\n",
    "            logprobs = F.log_softmax(logits[0, -1] / self.temp, dim=-1)\n",
    "            \n",
    "            candidates = logprobs.topk(self.beam_size)\n",
    "            \n",
    "            for token_score, token_idx in zip(candidates.values, candidates.indices):\n",
    "                \n",
    "                token_idx = int(token_idx)\n",
    "\n",
    "                new_score = cur_partial_score - float(token_score)\n",
    "                new_hyp = cur_partial_hyp + [token_idx]\n",
    "                new_item = (new_score, new_hyp)\n",
    "\n",
    "                if token_idx == self.model.decoder.tokenizer.eos_id() or len(new_hyp) - 1 >= self.max_steps:\n",
    "                    final_hyps.append(new_item)\n",
    "                else:\n",
    "                    heapq.heappush(partial_hyps, new_item)\n",
    "            \n",
    "            if len(partial_hyps) > self.beam_size:\n",
    "                partial_hyps = heapq.nsmallest(self.beam_size, partial_hyps)\n",
    "                heapq.heapify(partial_hyps)\n",
    "\n",
    "        final_scores, final_token_lists = zip(*final_hyps)\n",
    "        \n",
    "        final_texts = self.model.decoder.tokenizer.decode(final_token_lists)\n",
    "\n",
    "        result = list(zip(final_scores, final_texts))\n",
    "        result.sort()\n",
    "\n",
    "        return result[:self.beam_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = BeamSearchDecoder(model, temp=1, beam_size=10)\n",
    "\n",
    "for i in range(features.shape[0]):\n",
    "\n",
    "    encoder_states = encoded[\n",
    "        [i],\n",
    "        :encoded_len[i],\n",
    "        :\n",
    "    ]\n",
    "    \n",
    "    ref_tokens = targets[i, :target_len[i]].tolist()\n",
    "    \n",
    "    print(f\"reference   : {tokenizer.decode(ref_tokens)}\")\n",
    "    for k, (score, hyp) in enumerate(decoder(encoder_states)):\n",
    "        print(f\"hypothesis {k + 1}: {hyp} {score:.2f}\")\n",
    "    print(\"#\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61068ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
