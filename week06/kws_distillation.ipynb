{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00f9aae1",
   "metadata": {},
   "source": [
    "* [pytorch tutorials](https://pytorch.org/tutorials/)\n",
    "* [torchaudio](https://pytorch.org/audio/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec63b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# pip install torch==1.12.1\n",
    "# pip install torchaudio==0.12.1\n",
    "# pip install omegaconf==2.2.3\n",
    "# pip install --upgrade git+https://github.com/Lyken17/pytorch-OpCounter.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05692380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Optional, Callable, Dict, List, Any, Tuple\n",
    "\n",
    "import omegaconf\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "import thop\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9788e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 777\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2adece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Model:\n",
    "    kernels: Tuple[int]\n",
    "    strides: Tuple[int]\n",
    "    channels: Tuple[int]\n",
    "    hidden_size: int\n",
    "    activation: str\n",
    "\n",
    "@dataclass\n",
    "class Optim:\n",
    "    lr: float\n",
    "    n_epochs: int\n",
    "    batch_size: int\n",
    "        \n",
    "@dataclass\n",
    "class Features:\n",
    "    n_fft: int\n",
    "    win_length: int\n",
    "    hop_length: int\n",
    "    n_mels: int\n",
    "\n",
    "@dataclass\n",
    "class Augmentations:\n",
    "    freq_mask_param: int\n",
    "    time_mask_param: int\n",
    "    min_gain: float\n",
    "    max_gain: float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048915cb",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320ee337",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpotterDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "            self, manifest_path: Path, idx_to_keyword: List[str],\n",
    "            transform, ids: Optional[List[int]] = None\n",
    "        ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "        manifest = pd.read_csv(manifest_path)\n",
    "        if ids is not None:\n",
    "            manifest = manifest.loc[ids]\n",
    "        self.wav_files = [\n",
    "            manifest_path.parent / wav_path for wav_path in manifest.path\n",
    "        ]\n",
    "        \n",
    "        keyword_to_idx = {\n",
    "            keyword: idx for idx, keyword in enumerate(idx_to_keyword)\n",
    "        }\n",
    "        self.labels = [\n",
    "            keyword_to_idx[keyword] for keyword in manifest.label\n",
    "        ]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.wav_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        wav, sr = torchaudio.load(self.wav_files[idx])\n",
    "        features = self.transform(wav)\n",
    "        return wav[0], features, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a50bef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collator(data):\n",
    "    specs = []\n",
    "    labels = []\n",
    "\n",
    "    for wav, features, label in data:\n",
    "        specs.append(features)\n",
    "        labels.append(label)\n",
    "\n",
    "    specs = torch.cat(specs)  \n",
    "    labels = torch.Tensor(labels).long()\n",
    "    return specs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8946d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecScaler(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.log(x.clamp_(1e-9, 1e9))\n",
    "\n",
    "class RandomGain(torch.nn.Module):\n",
    "    def __init__(self, min_gain: float=0.5, max_gain: float=1.0):\n",
    "        super().__init__()\n",
    "        self.min_gain = min_gain\n",
    "        self.max_gain = max_gain\n",
    "\n",
    "    def forward(self, audio: torch.Tensor) -> torch.Tensor:  \n",
    "        gain = random.uniform(self.min_gain, self.max_gain / audio.abs().max())\n",
    "        audio = torchaudio.transforms.Vol(gain, gain_type=\"amplitude\")(audio)\n",
    "        return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157e1112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloaders(conf: omegaconf.DictConfig) -> Tuple[torch.utils.data.DataLoader]:\n",
    "    \n",
    "    train_transform = torch.nn.Sequential(\n",
    "        RandomGain(min_gain=conf.augs.min_gain, max_gain=conf.augs.max_gain),\n",
    "        torchaudio.transforms.MelSpectrogram(sample_rate=conf.sample_rate, **conf.features),\n",
    "        torchaudio.transforms.FrequencyMasking(freq_mask_param=conf.augs.freq_mask_param),\n",
    "        torchaudio.transforms.TimeMasking(time_mask_param=conf.augs.time_mask_param),\n",
    "        SpecScaler()\n",
    "    )\n",
    "\n",
    "    val_transform = torch.nn.Sequential(\n",
    "        torchaudio.transforms.MelSpectrogram(sample_rate=conf.sample_rate, **conf.features),\n",
    "        SpecScaler()\n",
    "    )\n",
    "    \n",
    "    dataset = SpotterDataset(\n",
    "        manifest_path=Path(conf.train_manifest),\n",
    "        idx_to_keyword=conf.idx_to_keyword,\n",
    "        transform=train_transform\n",
    "    )\n",
    "    \n",
    "    val_count = int(len(dataset) * conf.val_fraction)\n",
    "    ids = torch.randperm(len(dataset), generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "    val_ids = ids[:val_count]\n",
    "    train_ids = ids[val_count:]\n",
    "\n",
    "    train_dataset = SpotterDataset(\n",
    "        manifest_path=Path(conf.train_manifest),\n",
    "        idx_to_keyword=conf.idx_to_keyword,\n",
    "        transform=train_transform,\n",
    "        ids=train_ids\n",
    "    )\n",
    "\n",
    "    val_dataset = SpotterDataset(\n",
    "        manifest_path=Path(conf.train_manifest),\n",
    "        idx_to_keyword=conf.idx_to_keyword,\n",
    "        transform=val_transform,\n",
    "        ids=val_ids\n",
    "    )\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=conf.optim.batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collator,\n",
    "    )\n",
    "\n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=val_dataset,\n",
    "        batch_size=conf.optim.batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collator,\n",
    "    )\n",
    "    \n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba9ba6",
   "metadata": {},
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42954ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, criterion, optimizer, loader, device, epoch_index, tb_writer, log_interval=100):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.\n",
    "    running_true_preds, running_preds = 0, 0\n",
    "    last_loss, last_acc = 0., 0.\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(loader):\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(inputs)\n",
    "        preds = logits.argmax(1)\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_true_preds += (preds == labels).sum()\n",
    "        running_preds += torch.numel(preds)\n",
    "        \n",
    "        if i % log_interval == log_interval - 1:\n",
    "            last_loss = running_loss / log_interval\n",
    "            last_acc = running_true_preds / running_preds \n",
    "            tb_x = epoch_index * len(loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            tb_writer.add_scalar('Accuracy/train', last_acc, tb_x)\n",
    "            running_loss = 0.\n",
    "            running_true_preds, running_preds = 0, 0\n",
    "\n",
    "    return last_loss, last_acc\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation(model, criterion, loader, device, epoch_index, tb_writer):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.\n",
    "    running_true_preds, running_preds = 0, 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(loader):\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        logits = model(inputs)\n",
    "        preds = logits.argmax(1)\n",
    "        \n",
    "        running_loss += criterion(logits, labels).item()\n",
    "        running_true_preds += (preds == labels).sum()\n",
    "        running_preds += torch.numel(preds)\n",
    "        \n",
    "    loss = running_loss / len(loader)\n",
    "    acc = running_true_preds / running_preds \n",
    "    \n",
    "    tb_x = epoch_index + 1\n",
    "    tb_writer.add_scalar('Loss/val', loss, tb_x)\n",
    "    tb_writer.add_scalar('Accuracy/val', acc, tb_x)\n",
    "    \n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c12791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_logger_and_dump_params(conf, model, description=''):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    exp_dir = Path(f\"runs/{timestamp}{'_' + description if description else ''}\")\n",
    "    ckpt_dir = exp_dir / \"ckpts\"\n",
    "    ckpt_dir.mkdir(parents=True)\n",
    "    with open(exp_dir / 'conf.yaml', 'w') as f:\n",
    "        omegaconf.OmegaConf.save(config=conf, f=f)\n",
    "\n",
    "    tb_writer = SummaryWriter(exp_dir)\n",
    "    \n",
    "    rand_features = torch.randn(1, conf.features.n_mels, conf.sample_rate // conf.features.hop_length + 1)\n",
    "    macs, params = thop.profile(\n",
    "        model,\n",
    "        inputs=(rand_features.to(conf.device),)\n",
    "    )\n",
    "\n",
    "    tb_writer.add_scalar('MACs', macs, 0)\n",
    "    tb_writer.add_scalar('Params', params, 0)\n",
    "    return ckpt_dir, tb_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bac5d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(conf, model, criterion, optimizer, train_dataloader, val_dataloader, description=''):\n",
    "    \n",
    "    ckpt_dir, tb_writer = init_logger_and_dump_params(conf, model, description=description)\n",
    "\n",
    "    best_val_acc = -1.\n",
    "\n",
    "    for epoch in range(conf.optim.n_epochs):\n",
    "\n",
    "        avg_loss, avg_acc = train_one_epoch(\n",
    "            model, criterion, optimizer, train_dataloader,\n",
    "            conf.device, epoch, tb_writer\n",
    "        )\n",
    "\n",
    "        val_loss, val_acc = validation(\n",
    "            model, criterion, val_dataloader,\n",
    "            conf.device, epoch, tb_writer\n",
    "        )\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                ckpt_dir / f\"model_epoch_{epoch + 1}_val_acc_{val_acc:.3f}.ckpt\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb87d654",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a3a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1dNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features, n_classes, conf: omegaconf.dictconfig.DictConfig):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        activation = getattr(torch.nn, conf.activation)()\n",
    "        \n",
    "        features = in_features\n",
    "        \n",
    "        module_list = []\n",
    "        \n",
    "        for kernel_size, stride, channels in zip(conf.kernels, conf.strides, conf.channels):\n",
    "            \n",
    "            module_list.extend([\n",
    "                torch.nn.Conv1d(\n",
    "                    in_channels=features, out_channels=features, kernel_size=kernel_size,\n",
    "                    stride=stride, groups=features\n",
    "                ),\n",
    "                activation,\n",
    "                torch.nn.Conv1d(in_channels=features, out_channels=channels, kernel_size=1),\n",
    "                torch.nn.BatchNorm1d(num_features=channels),\n",
    "                activation,\n",
    "                torch.nn.MaxPool1d(kernel_size=stride)\n",
    "            ])\n",
    "            \n",
    "            features = channels\n",
    "\n",
    "        module_list.extend([\n",
    "            torch.nn.AdaptiveAvgPool1d(1),\n",
    "            torch.nn.Flatten(),\n",
    "\n",
    "            torch.nn.Linear(channels, conf.hidden_size),\n",
    "            activation,\n",
    "            torch.nn.Linear(conf.hidden_size, n_classes),\n",
    "        ])\n",
    "        \n",
    "        self.model = torch.nn.Sequential(*module_list)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff767d0",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "download from [kaggle](https://www.kaggle.com/t/830d20b353bd4e0d80630a97835f14a6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09060fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf test train\n",
    "unzip -q train.zip\n",
    "unzip -q test.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d33dfbb",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e983ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DistillConfig:\n",
    "    weight: float = 0.1\n",
    "    softmax_temp: float = 10\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExpConfig:\n",
    "    \n",
    "    model: Model\n",
    "    \n",
    "    train_manifest: str = 'train/manifest_.csv'\n",
    "    \n",
    "    sample_rate: int = 16_000\n",
    "    val_fraction: float = 0.1\n",
    "    idx_to_keyword: List[str] = ('sber', 'joy', 'afina', 'salut', 'filler')\n",
    "    device: str = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    optim: Optim = Optim(\n",
    "        lr=1e-3, n_epochs=20, batch_size=64\n",
    "    )\n",
    "    features: Features = Features(\n",
    "        n_fft=400, win_length=400, hop_length=160, n_mels=64\n",
    "    )\n",
    "    augs: Augmentations = Augmentations(\n",
    "        freq_mask_param=0, time_mask_param=0,\n",
    "        min_gain=0.5, max_gain=1.0\n",
    "    )\n",
    "    distill: DistillConfig = DistillConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594f516",
   "metadata": {},
   "source": [
    "## Train Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ef0d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model_cfg = Model(\n",
    "    kernels=[3, 3, 3, 3],\n",
    "    strides=[2, 2, 1, 1],\n",
    "    channels=[32, 32, 64, 128],\n",
    "    hidden_size=16,\n",
    "    activation='ReLU'\n",
    ")\n",
    "teacher_conf = omegaconf.OmegaConf.structured(ExpConfig(model=teacher_model_cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e28aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader = prepare_dataloaders(teacher_conf)\n",
    "teacher_model = (\n",
    "    Conv1dNet(\n",
    "        in_features=teacher_conf.features.n_mels, \n",
    "        n_classes=len(teacher_conf.idx_to_keyword),\n",
    "        conf=teacher_conf.model\n",
    "    )\n",
    "    .to(teacher_conf.device)\n",
    ")\n",
    "optimizer = torch.optim.Adam(params=teacher_model.parameters(), lr=teacher_conf.optim.lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_loop(\n",
    "    teacher_conf, teacher_model, criterion, optimizer,\n",
    "    train_dataloader, val_dataloader, description='teacher'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503672f6",
   "metadata": {},
   "source": [
    "## Train Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c02401",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model_cfg = Model(\n",
    "    kernels=[3],\n",
    "    strides=[4],\n",
    "    channels=[16],\n",
    "    hidden_size=16,\n",
    "    activation='ReLU'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf75cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_conf = omegaconf.OmegaConf.structured(ExpConfig(model=student_model_cfg))\n",
    "train_dataloader, val_dataloader = prepare_dataloaders(student_conf)\n",
    "student_model = (\n",
    "    Conv1dNet(\n",
    "        in_features=student_conf.features.n_mels, \n",
    "        n_classes=len(student_conf.idx_to_keyword),\n",
    "        conf=student_conf.model\n",
    "    )\n",
    "    .to(student_conf.device)\n",
    ")\n",
    "optimizer = torch.optim.Adam(params=student_model.parameters(), lr=student_conf.optim.lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_loop(\n",
    "    student_conf, student_model, criterion, optimizer,\n",
    "    train_dataloader, val_dataloader, description='student'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1400eb24",
   "metadata": {},
   "source": [
    "## Distill Teacher Into Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d63cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = (\n",
    "    Conv1dNet(\n",
    "        in_features=teacher_conf.features.n_mels, \n",
    "        n_classes=len(teacher_conf.idx_to_keyword),\n",
    "        conf=teacher_conf.model\n",
    "    )\n",
    "    .to(teacher_conf.device)\n",
    ")\n",
    "\n",
    "teacher_model.load_state_dict(\n",
    "    torch.load('runs/20221011_113801_teacher/ckpts/model_epoch_9_val_acc_0.903.ckpt'),\n",
    "    strict=False\n",
    ")\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6022d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_conf = omegaconf.OmegaConf.structured(\n",
    "    ExpConfig(\n",
    "        model=student_model_cfg,\n",
    "        distill=DistillConfig(weight=0.90, softmax_temp=10)\n",
    "    )\n",
    ")\n",
    "train_dataloader, val_dataloader = prepare_dataloaders(student_conf)\n",
    "\n",
    "student_model = (\n",
    "    Conv1dNet(\n",
    "        in_features=student_conf.features.n_mels, \n",
    "        n_classes=len(student_conf.idx_to_keyword),\n",
    "        conf=student_conf.model\n",
    "    )\n",
    "    .to(student_conf.device)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(params=student_model.parameters(), lr=student_conf.optim.lr)\n",
    "student_criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5acf1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch_kd(\n",
    "        model, teacher_model, distill_conf, student_criterion, optimizer, loader,\n",
    "        device, epoch_index, tb_writer, log_interval=100\n",
    "    ):\n",
    "    \n",
    "    kd_criterion = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "    \n",
    "    T = distill_conf.softmax_temp\n",
    "    \n",
    "    model.train()\n",
    "    teacher_model.eval()\n",
    "    \n",
    "    running_loss = 0.\n",
    "    running_sum_loss = 0.\n",
    "    running_kd_loss = 0.\n",
    "    running_true_preds, running_preds = 0, 0\n",
    "    last_loss, last_acc = 0., 0.\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(loader):\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(inputs)\n",
    "        preds = logits.argmax(1)\n",
    "        student_loss = student_criterion(logits, labels)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            teacher_probs = F.softmax(teacher_model(inputs) / T, dim=1)\n",
    "        \n",
    "        kd_loss = kd_criterion(F.log_softmax(logits / T, dim=1), teacher_probs)\n",
    "        \n",
    "        loss = (1 - distill_conf.weight) * student_loss + distill_conf.weight * kd_loss * T ** 2\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += student_loss.item()\n",
    "        running_kd_loss += kd_loss.item()\n",
    "        running_sum_loss += loss.item()\n",
    "        running_true_preds += (preds == labels).sum()\n",
    "        running_preds += torch.numel(preds)\n",
    "        \n",
    "        if i % log_interval == log_interval - 1:\n",
    "            last_loss = running_loss / log_interval\n",
    "            last_kd_loss = running_kd_loss / log_interval\n",
    "            last_sum_loss = running_sum_loss / log_interval\n",
    "            last_acc = running_true_preds / running_preds \n",
    "            tb_x = epoch_index * len(loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            tb_writer.add_scalar('Loss_kd/train', last_kd_loss, tb_x)\n",
    "            tb_writer.add_scalar('Loss_sum/train', last_sum_loss, tb_x)\n",
    "            tb_writer.add_scalar('Accuracy/train', last_acc, tb_x)\n",
    "            running_loss, running_kd_loss, running_sum_loss = 0., 0., 0.\n",
    "            running_true_preds, running_preds = 0, 0\n",
    "\n",
    "    return last_loss, last_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679ad021",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir, tb_writer = init_logger_and_dump_params(student_conf, student_model, description='student_distillation')\n",
    "\n",
    "best_val_acc = -1.\n",
    "\n",
    "for epoch in range(student_conf.optim.n_epochs):\n",
    "\n",
    "    avg_loss, avg_acc = train_one_epoch_kd(\n",
    "        student_model, teacher_model, student_conf.distill, student_criterion, optimizer, \n",
    "        train_dataloader, student_conf.device, epoch, tb_writer\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc = validation(\n",
    "        student_model, student_criterion, val_dataloader,\n",
    "        student_conf.device, epoch, tb_writer\n",
    "    )\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(\n",
    "            student_model.state_dict(),\n",
    "            ckpt_dir / f\"model_epoch_{epoch + 1}_val_acc_{val_acc:.3f}.ckpt\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f17c1",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235864a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter through val_dataloader\n",
    "# plot confusion matrix\n",
    "# listen to misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e390ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
